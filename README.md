# 🚀 A# 🚀 AdventureWorks Performance Dashboard

This repository showcases a full-scale data Engineer  project using the **AdventureWorks dataset**, built entirely on the Azure data platform. The goal is to create an end-to-end pipeline for data ingestion, transformation, storage, and visualization using enterprise-grade tools.

---

## 🎯 Project Objective

To design a cloud-based performance dashboard using the AdventureWorks dataset, highlighting sales, product trends, customer behavior, and operational insights. The project leverages Azure-native services for a complete modern data platform implementation.

---

## 🧰 Tools & Technologies Used

- **Azure Data Factory** – For orchestrating ETL workflows  
- **Azure Data Lake Storage Gen2** – Centralized data storage (Bronze, Silver, Gold layers)  
- **Azure Databricks** – Data transformation using PySpark notebooks  
- **Azure Synapse Analytics** – Querying and modeling structured data for reporting  
- **Power BI** – Interactive dashboard and performance reporting  
- **AdventureWorks Dataset** – Source business data (Excel/CSV)

---

## 📊 Key Features

- 📥 Automated data ingestion from source to Data Lake  
- 🔄 Data cleansing and transformation in Databricks (PySpark)  
- 🧮 Dimensional modeling and data marts in Synapse SQL  
- 📈 Power BI reports showing sales, profit, and customer KPIs  
- 🎛️ Dynamic filters and slicers for interactivity  

---

## 📸 Sample Screenshots

### 🔹 Sales Overview  
![Sales Overview](Screenshots/sales-overview.png)

### 🔹 Profit by Region  
![Profit by Region](Screenshots/profit-by-region.png)

### 🔹 Product Performance  
![Product Performance](Screenshots/product-performance.png)

---

## 📁 Folder Structure



---

## 🎯 Project Objective

To build a scalable, cloud-based data pipeline that ingests raw data, processes it efficiently, and visualizes business-critical insights for decision-making. This project showcases the integration of various Azure services to handle ETL and reporting tasks.

---

## 🧰 Tools & Technologies Used

- **Azure Data Factory** – For orchestrating data movement and transformation pipelines  
- **Azure Data Lake Storage Gen2** – As a centralized data repository (Bronze/Silver/Gold layers)  
- **Azure Databricks** – For data wrangling, cleansing, and applying business logic (PySpark)  
- **Azure Synapse Analytics** – For data integration and performance-tuned queries  
- **Power BI** – For interactive reporting and business intelligence  
- **AdventureWorks Dataset** – Source dataset in Excel format  

---

## 📊 Key Features

- Automated data ingestion from source to Data Lake  
- Multi-stage data transformation using PySpark notebooks in Databricks  
- ETL pipeline orchestration using ADF  
- Data aggregation and modeling in Synapse SQL  
- Dynamic, filterable reports and dashboards in Power BI  

---




